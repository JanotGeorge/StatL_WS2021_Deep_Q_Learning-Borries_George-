import random as rd
import numpy as np
import matplotlib.pyplot as plt
#=============================================================================================================
labyrinth2 = np.array([  # 15x22 Matrix
    [2, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1],
    [1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1],
    [1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1],
    [1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1],
    [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
    [1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1],
    [1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1],
    [1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1],
    [1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1],
    [1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1],
    [1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],
    [1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1],
    [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 3]
])

labyrinth = np.array([  # 31x46 Matrix
    [2, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],
    [1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0,
        1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1],
    [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0,
        1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1],
    [1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1,
        1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1],
    [1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,
        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1],
    [1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0,
        1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1],
    [1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0,
        0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1],
    [1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1,
        1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1],
    [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
        1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],
    [1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1,
        1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1],
    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1],
    [1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1,
        1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1],
    [1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1],
    [1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
    [1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,
        0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1],
    [1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,
        1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1],
    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
        0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1],
    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1,
        1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1],
    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1],
    [1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0,
        1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1],
    [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,
        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
    [1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1,
        1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
    [1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0,
        1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],
    [1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0,
        1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1],
    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
        1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
    [1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1],
    [1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
        1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1],
    [1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1],
    [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 3],
])
#generiert durch: Maze Generator, https://www.dcode.fr/maze-generator , letzter Aufruf 14.12.2021
#=============================================================================================================
Episodenanzahl = 700  # Anzahl der Durchläufe
epsilon_max = 1  # Starterkundungsrate
epsilon_red = 0.01  # Erkundungsreduktion
epsilon_min = 0  # Minimale Erkundungsrate
gamma = 1  # Diskontierungsfaktor
alpha = 0.5  # Lernrate
max_Schritte = 500  # Abbruchparameter
ziel_erreicht = 100  # Belohnung
kollision = -1  # Bestrafung
laufen = -0.01  # Bestrafung
#=============================================================================================================
Belohnungsvektor = []
Kollisionen = []
Schrittzähler = []
Ziel_check = []
Epsilon_Prozent = []
#=============================================================================================================
Aktionen = (
    [0, 1],  # rechts
    [-1, 0],  # oben
    [0, -1],  # links
    [1, 0]  # unten
)
#=============================================================================================================


class QLLS(object):
    def __init__(self):
        self.Episodennummer = 1
        self.epsilon = epsilon_max
        self.q_tabelle = np.zeros((labyrinth.size, len(Aktionen)))

        self.laby_Reihen, self.laby_Spalten = labyrinth.shape
        self.Wegfelder = [[r, s] for r in range(self.laby_Reihen) for s in range(
            self.laby_Spalten) if not labyrinth[r, s] == 1]

        yz = [r for r in range(self.laby_Reihen) if any(labyrinth[r, :] == 3)]
        xz = [s for s in range(self.laby_Spalten) if any(labyrinth[:, s] == 3)]
        self.Zielfeld = [yz[0], xz[0]]

        ys = [r for r in range(self.laby_Reihen) if any(labyrinth[r, :] == 2)]
        xs = [s for s in range(self.laby_Spalten) if any(labyrinth[:, s] == 2)]
        self.Startzustand = [ys[0], xs[0], 'laufen']

    def Neustart(self):
        self.Belohnung_Gesamt = 0
        self.kollision_counter = 0
        self.Schrittanzahl = 0
        self.Zustand = self.Startzustand.copy()

    def Belohnungserhalt(self):
        if self.Zustand[2] == 'laufen':
            return laufen
        elif self.Zustand[2] == 'kollision':
            self.kollision_counter += 1
            return kollision
        elif self.Zustand[2] == 'ziel_erreicht':
            return ziel_erreicht

    def Erkundung_verringern(self):
        self.epsilon = epsilon_min + \
            (epsilon_max - epsilon_min) / \
            np.exp(epsilon_red * self.Episodennummer)

    def Dokumentation(self):
        Belohnungsvektor.append([self.Episodennummer, self.Belohnung_Gesamt])
        Schrittzähler.append([self.Episodennummer, self.Schrittanzahl])
        Kollisionen.append([self.Episodennummer, self.kollision_counter])
        Ziel_check.append([self.Episodennummer, self.Zustand[2]])
        Epsilon_Prozent.append([self.Episodennummer, (self.epsilon*100)])

    def Bewegung(self):
        self.Zustand_alt = self.Zustand.copy()
        if list(np.add([self.Zustand[0], self.Zustand[1]], self.Aktion)) in self.Wegfelder:
            self.Zustand[0] += self.Aktion[0]
            self.Zustand[1] += self.Aktion[1]
            if [self.Zustand[0], self.Zustand[1]] == self.Zielfeld:
                self.Zustand[2] = 'ziel_erreicht'
            else:
                self.Zustand[2] = 'laufen'
        else:
            self.Zustand[2] = 'kollision'

    def Q_Tabelle_aktualiesieren(self):
        q_position_alt = self.Zustand_alt[0] * \
            self.laby_Spalten + self.Zustand_alt[1]
        q_position = self.Zustand[0] * self.laby_Spalten + self.Zustand[1]

        self.q_tabelle[q_position_alt, self.Richtung] = (1-alpha) * self.q_tabelle[q_position_alt, self.Richtung] + \
            alpha * (self.Belohnungserhalt() + gamma *
                     np.max(self.q_tabelle[q_position, :]))

    def Abbruch(self):
        if self.Schrittanzahl >= max_Schritte or self.Zustand[2] == 'ziel_erreicht':
            return True
        else:
            return False

    def Exploration_vs_Exploitation(self):
        if rd.random() < self.epsilon:
            self.Richtung = rd.choice(range(len(Aktionen)))
        else:
            q_position = self.Zustand[0] * self.laby_Spalten + self.Zustand[1]
            self.Richtung = np.argmax(self.q_tabelle[q_position, :])
        self.Aktion = Aktionen[self.Richtung]

    def Durchlauf(self):
        while self.Episodennummer <= Episodenanzahl:
            self.Neustart()
            while not self.Abbruch():
                self.Schrittanzahl += 1
                self.Exploration_vs_Exploitation()
                self.Bewegung()
                self.Belohnung_Gesamt += self.Belohnungserhalt()
                self.Q_Tabelle_aktualiesieren()
            self.Dokumentation()
            self.Erkundung_verringern()
            self.Episodennummer += 1


#=============================================================================================================

#plt.imshow(labyrinth)
#plt.xticks([])
#plt.yticks([])
#plt.show()
#plt.imshow(labyrinth2)
#plt.xticks([])
#plt.yticks([])
#plt.show()
Test = QLLS()
Test.Durchlauf()
plt.plot([row[0] for row in Schrittzähler], [row[1]
         for row in Schrittzähler], 'y', label='Anzahl der Schritte')
plt.plot([row[0] for row in Belohnungsvektor], [row[1]
         for row in Belohnungsvektor], 'g', label='Höhe der Belohnung')
plt.plot([row[0] for row in Kollisionen], [row[1]
         for row in Kollisionen], 'r', label='Anzahl der Kollisionen')
plt.plot([row[0] for row in Epsilon_Prozent], [row[1]
         for row in Epsilon_Prozent], 'b', label='Erkundungsrate in %')
plt.xlabel('Episoden')
plt.legend()
plt.show()
